import torch
import torch.nn as nn

NUM_CLASSES = 10

class MLP(nn.Module):
    def __init__(self, num_classes=NUM_CLASSES):
        super(MLP, self).__init__()     
        self.flatten = nn.Flatten()
        self.fc1 = nn.Linear(32 * 32 * 3, 200)
        self.fc2 = nn.Linear(200, 150)
        self.fc3 = nn.Linear(150, num_classes)

    def forward(self, x):
        x = self.flatten(x)
        x = torch.relu(self.fc1(x))
        x = torch.relu(self.fc2(x))
        x = torch.softmax(self.fc3(x), dim=1)
        return x